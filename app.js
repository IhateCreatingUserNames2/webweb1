const express = require("express");
const bodyParser = require("body-parser");
const { PineconeClient } = require("@pinecone-database/pinecone"); // Correct import
const fetch = require("node-fetch");
const fs = require("fs");
const path = require("path");
const csvParser = require("csv-parser");

const app = express();
const PORT = process.env.PORT || 3000;

// API Keys
const MINI_MAX_API_KEY = process.env.MiniMax_API_KEY;
const PINECONE_API_KEY = process.env.PINECONE_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// Pinecone Configuration
const PINECONE_ENVIRONMENT = process.env.PINECONE_ENVIRONMENT || "us-east-1"; // Set to 'us-east-1' as per your setup
const PINECONE_HOST_BLUEW = "https://bluew-xek6roj.svc.aped-4627-b74a.pinecone.io"; // Host for BlueW index
const PINECONE_HOST_BLUEW2 = "https://bluew2-xek6roj.svc.aped-4627-b74a.pinecone.io"; // Host for BlueW2 index
const INDEX_NAME_BLUEW = "bluew"; // Index for dense vector search
const INDEX_NAME_BLUEW2 = "bluew2"; // Index for hybrid (sparse-dense) search

const UPLOADS_DIR = path.join(__dirname, "uploads"); // Directory for uploaded files

// Allowed OpenAI models
const ALLOWED_MODELS = ["gpt-4o", "chatgpt-4o-latest", "o1"];

// Check for required API keys
if (!PINECONE_API_KEY || !OPENAI_API_KEY || !MINI_MAX_API_KEY) {
  console.error("‚ùå Missing API keys. Set them in the environment variables.");
  process.exit(1);
}

// Initialize Pinecone clients
const pineconeBlueW = new PineconeClient();
const pineconeBlueW2 = new PineconeClient();

(async () => {
  try {
    // Initialize Pinecone Clients
    await pineconeBlueW.init({
      apiKey: PINECONE_API_KEY,
      environment: PINECONE_ENVIRONMENT,
    });

    await pineconeBlueW2.init({
      apiKey: PINECONE_API_KEY,
      environment: PINECONE_ENVIRONMENT,
    });

    console.log("‚úÖ Pinecone clients initialized successfully.");

    // Start the server after Pinecone initialization
    app.listen(PORT, () => {
      console.log(`üöÄ Server running at: http://localhost:${PORT}`);
    });
  } catch (error) {
    console.error("‚ùå Error initializing Pinecone clients:", error.message);
    process.exit(1);
  }
})();

// Middleware
app.use(bodyParser.json());
app.use(express.static(__dirname));

// Serve index.html
app.get("/", (req, res) => {
  res.sendFile(path.join(__dirname, "index.html"));
});

// Chat history storage
const chatHistory = [];

/**
 * ‚úÖ Fetch context from stored files
 * Scans .txt and .csv files in /uploads/ for relevant content based on the user's message.
 * @param {string} message - The user's input message.
 * @returns {string|null} - Combined relevant context or null if none found.
 */
async function fetchFileContext(message) {
  try {
    let relevantContext = [];

    // Ensure the uploads directory exists
    if (!fs.existsSync(UPLOADS_DIR)) {
      console.warn(`‚ö†Ô∏è Uploads directory not found at ${UPLOADS_DIR}. Skipping file-based context retrieval.`);
      return null;
    }

    // Read all .txt files
    const txtFiles = fs.readdirSync(UPLOADS_DIR).filter((file) => file.endsWith(".txt"));
    for (const file of txtFiles) {
      const filePath = path.join(UPLOADS_DIR, file);
      const content = fs.readFileSync(filePath, "utf-8");

      // Simple keyword search (case-insensitive)
      if (content.toLowerCase().includes(message.toLowerCase())) {
        const excerpt = content.length > 500 ? content.substring(0, 500) + "..." : content;
        relevantContext.push(`üìå From ${file}: ${excerpt}`);
      }
    }

    // Read all .csv files
    const csvFiles = fs.readdirSync(UPLOADS_DIR).filter((file) => file.endsWith(".csv"));
    for (const file of csvFiles) {
      const filePath = path.join(UPLOADS_DIR, file);
      const csvData = [];

      // Parse CSV asynchronously
      await new Promise((resolve, reject) => {
        fs.createReadStream(filePath)
          .pipe(csvParser())
          .on("data", (row) => {
            const rowContent = JSON.stringify(row).toLowerCase();
            if (rowContent.includes(message.toLowerCase())) {
              csvData.push(JSON.stringify(row));
            }
          })
          .on("end", () => {
            if (csvData.length) {
              const excerpts = csvData.slice(0, 5).join("\n");
              relevantContext.push(`üìå From ${file}:\n${excerpts}`);
            }
            resolve();
          })
          .on("error", (err) => {
            console.error(`‚ùå Error reading CSV file ${file}:`, err.message);
            reject(err);
          });
      });
    }

    return relevantContext.length ? relevantContext.join("\n\n") : null;
  } catch (error) {
    console.error("‚ùå Error in fetchFileContext:", error.message);
    return null;
  }
}

/**
 * üõ†Ô∏è Fetch relevant context from both Pinecone indexes and uploaded files
 * @param {string} message - The user's input message.
 * @returns {string|null} - Combined relevant context or null if none found.
 */
async function fetchContext(message) {
  try {
    const indexBlueW = pineconeBlueW.Index(INDEX_NAME_BLUEW);
    const indexBlueW2 = pineconeBlueW2.Index(INDEX_NAME_BLUEW2);

    // üß† Get query embedding from OpenAI
    const embeddingResponse = await fetch("https://api.openai.com/v1/embeddings", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify({ input: message, model: "text-embedding-ada-002" }),
    });

    const embeddingData = await embeddingResponse.json();
    if (!embeddingData.data || embeddingData.data.length === 0) {
      throw new Error("üö® No embedding data received from OpenAI.");
    }

    const queryVector = embeddingData.data[0].embedding;

    // üîç Query BlueW (Dense Vector Search)
    const pineconeResponseBlueW = await indexBlueW.query({
      vector: queryVector,
      topK: 5, // Adjust based on your needs
      includeMetadata: true,
      includeValues: false,
    });

    console.log("üîç Pinecone BlueW Raw Response:", JSON.stringify(pineconeResponseBlueW, null, 2));

    // üîç Query BlueW2 (Hybrid Search)
    // If you have a method to generate a valid sparse vector, implement it here.
    // For demonstration, we'll assume no sparse vector is provided.
    let pineconeResponseBlueW2;
    let hybridData = null;

    // Example: Only perform hybrid search if you have a valid sparse vector
    // Replace the following with your actual logic to create a sparse vector
    const hasSparseVector = false; // Set to true if you have a sparse vector

    if (hasSparseVector) {
      const sparseVector = {
        indices: [10, 45, 16], // Example sparse indices
        values: [0.5, 0.5, 0.2], // Example sparse values
      };

      // Validate sparse vector
      if (sparseVector.indices.length && sparseVector.values.length) {
        pineconeResponseBlueW2 = await fetch(`${PINECONE_HOST_BLUEW2}/query`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Api-Key": PINECONE_API_KEY,
          },
          body: JSON.stringify({
            vector: queryVector,
            topK: 5, // Adjust based on your needs
            includeMetadata: true,
            includeValues: false,
            sparseVector: sparseVector,
          }),
        });

        hybridData = await pineconeResponseBlueW2.json();
        console.log("üîç Pinecone BlueW2 Raw Response (Hybrid Search):", JSON.stringify(hybridData, null, 2));
      } else {
        console.warn("‚ö†Ô∏è Sparse vector is invalid. Skipping hybrid search.");
      }
    } else {
      console.log("‚ÑπÔ∏è No sparse vector provided. Skipping hybrid search.");
    }

    // üèÜ **Filter matches based on score**
    let relevantMatchesBlueW = [];
    if (pineconeResponseBlueW.matches) {
      relevantMatchesBlueW = pineconeResponseBlueW.matches
        .filter((match) => match.score > 0.4) // Example threshold for BlueW
        .map((match) => match.metadata.text);
    } else {
      console.warn("‚ö†Ô∏è No matches found in BlueW.");
    }

    console.log("üìå Relevant Context Found (BlueW):", relevantMatchesBlueW);

    // Handle hybrid search results
    let relevantMatchesBlueW2 = [];
    if (hybridData && hybridData.matches) {
      relevantMatchesBlueW2 = hybridData.matches
        .filter((match) => match.score > 0.1) // Example threshold for BlueW2
        .map((match) => match.metadata.text);
    } else {
      console.warn("‚ö†Ô∏è No matches found in BlueW2 or hybridData is undefined.");
    }

    console.log("üìå Relevant Context Found (BlueW2 - Hybrid):", relevantMatchesBlueW2);

    // ‚úÖ Fetch context from files
    const fileContext = await fetchFileContext(message);

    // üöÄ **Combine contexts with separators**
    const pineconeContext = [
      "### üìå Dense Vector Context (BlueW):",
      relevantMatchesBlueW.length ? relevantMatchesBlueW.join("\n") : "No relevant context found.",
      "### üìå Hybrid Search Context (BlueW2):",
      relevantMatchesBlueW2.length ? relevantMatchesBlueW2.join("\n") : "No relevant hybrid context found.",
    ].join("\n\n");

    const combinedContext = fileContext
      ? `${pineconeContext}\n\n### üìÇ File-based Context:\n${fileContext}`
      : pineconeContext;

    return combinedContext.length ? combinedContext : null;
  } catch (error) {
    console.error("‚ùå Error in fetchContext:", error.message);
    return null;
  }
}

/**
 * ü§ñ Generate response using OpenAI
 * @param {string} message - The user's input message.
 * @param {string|null} context - Combined relevant context.
 * @param {string} provider - The provider to use (e.g., 'openai').
 * @param {string} model - The OpenAI model to use.
 * @returns {string} - The generated response.
 */
async function generateResponse(message, context, provider, model) {
  chatHistory.push({ role: "user", content: message });

  // Maintain a maximum of 6 interactions
  if (chatHistory.length > 6) {
    chatHistory.splice(0, 2);
  }

  const MAX_CONTEXT_LENGTH = 2000;
  const trimmedContext = context ? context.substring(0, MAX_CONTEXT_LENGTH) : "";

  let systemMessage = `
Voc√™ √© Roberta, assistente virtual da BlueWidow Energia LTDA.
Forne√ßa informa√ß√µes sobre os servi√ßos da BlueWidow em energia solar, como geradores, usinas solares e etc...
--- c√°lculo da pot√™ncia da usina em KWP (quantidade de m√≥dulos):
consumo em kWh/m√™s dividido por (5.2 (irradia√ß√£o Goi√°s) x 30 (dias de gera√ß√£o) x 0.8 (fator perda do sistema)).
  `;

  // üõ†Ô∏è **Use Pinecone and File-based Context if Available**
  if (trimmedContext) {
    systemMessage += `
### üìå Informa√ß√µes Recuperadas:
${trimmedContext}

‚úÖ Use estas informa√ß√µes como base para a resposta. Se necess√°rio, pe√ßa mais detalhes ao usu√°rio.
    `;
  } else {
    // üõ†Ô∏è **Fallback: Allow OpenAI to answer freely**
    systemMessage += `
üîç Nenhuma informa√ß√£o espec√≠fica foi encontrada no banco de dados.
üí° Use seu conhecimento geral para responder de forma √∫til ao usu√°rio.
    `;
  }

  systemMessage += `
### üîç Hist√≥rico de Conversa:
${chatHistory
    .slice(-6)
    .map((msg) =>
      msg.role === "user" ? `üë§ Usu√°rio: ${msg.content}` : `ü§ñ Roberta: ${msg.content}`
    )
    .join("\n")}

üì¢ **Responda de forma clara e formatada em Markdown.**
`.trim();

  if (provider === "openai") {
    if (!ALLOWED_MODELS.includes(model)) {
      console.warn(`‚ö†Ô∏è Modelo inv√°lido "${model}" selecionado. Defaulting to gpt-4o.`);
      model = "gpt-4o";
    }

    const chatResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: model,
        messages: [
          { role: "system", content: systemMessage },
          ...chatHistory.slice(-6),
          { role: "user", content: message },
        ],
        max_tokens: 1500,
        temperature: 0.7,
      }),
    });

    const openaiData = await chatResponse.json();
    console.log("üí¨ OpenAI Response:", JSON.stringify(openaiData, null, 2));

    if (openaiData.choices?.[0]?.message?.content) {
      chatHistory.push({
        role: "assistant",
        content: openaiData.choices[0].message.content.trim(),
      });
      return openaiData.choices[0].message.content.trim();
    }

    return "Nenhuma resposta gerada.";
  } else {
    throw new Error("Invalid provider selected.");
  }
}

/**
 * üì® Chatbot API Endpoint
 * Receives user messages and returns chatbot responses.
 */
app.post("/chatbot", async (req, res) => {
  const { message, provider, model } = req.body;

  if (!message || !provider) {
    return res.status(400).json({ error: "Message, provider, and model are required." });
  }

  try {
    const context = await fetchContext(message);

    const reply = await generateResponse(message, context, provider, model);
    res.json({ reply });
  } catch (error) {
    console.error("‚ùå Error in /chatbot:", error.message);
    res.status(500).json({ error: "Ocorreu um erro ao processar sua solicita√ß√£o." });
  }
});
